{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANJU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5792 - auc: 0.5587 - loss: 0.8246 - precision: 0.6063 - recall: 0.6233 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.66667, saving model to best_mobilenetv2_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step - accuracy: 0.5796 - auc: 0.5608 - loss: 0.8236 - precision: 0.5955 - recall: 0.6239 - val_accuracy: 0.6667 - val_auc: 0.7500 - val_loss: 0.6010 - val_precision: 0.6429 - val_recall: 0.7500 - learning_rate: 3.0000e-04\n",
      "Epoch 2/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4866 - auc: 0.5459 - loss: 0.8156 - precision: 0.5508 - recall: 0.4655\n",
      "Epoch 2: val_accuracy improved from 0.66667 to 0.79167, saving model to best_mobilenetv2_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.5030 - auc: 0.5689 - loss: 0.7952 - precision: 0.5478 - recall: 0.4651 - val_accuracy: 0.7917 - val_auc: 0.7917 - val_loss: 0.5752 - val_precision: 0.8182 - val_recall: 0.7500 - learning_rate: 3.0000e-04\n",
      "Epoch 3/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6842 - auc: 0.6983 - loss: 0.6470 - precision: 0.6677 - recall: 0.7192\n",
      "Epoch 3: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.6882 - auc: 0.7102 - loss: 0.6381 - precision: 0.6772 - recall: 0.7116 - val_accuracy: 0.7500 - val_auc: 0.8368 - val_loss: 0.5373 - val_precision: 0.7500 - val_recall: 0.7500 - learning_rate: 3.0000e-04\n",
      "Epoch 4/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7351 - auc: 0.7500 - loss: 0.6000 - precision: 0.7579 - recall: 0.6548\n",
      "Epoch 4: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.7163 - auc: 0.7463 - loss: 0.6073 - precision: 0.7360 - recall: 0.6508 - val_accuracy: 0.7500 - val_auc: 0.8611 - val_loss: 0.5040 - val_precision: 0.7143 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 5/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7113 - auc: 0.7847 - loss: 0.5749 - precision: 0.6334 - recall: 0.7778\n",
      "Epoch 5: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.7123 - auc: 0.7826 - loss: 0.5698 - precision: 0.6579 - recall: 0.7626 - val_accuracy: 0.7500 - val_auc: 0.8750 - val_loss: 0.4786 - val_precision: 0.7143 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7221 - auc: 0.8006 - loss: 0.5457 - precision: 0.7498 - recall: 0.6674\n",
      "Epoch 6: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.7284 - auc: 0.8063 - loss: 0.5389 - precision: 0.7584 - recall: 0.6711 - val_accuracy: 0.7917 - val_auc: 0.8854 - val_loss: 0.4629 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7693 - auc: 0.8219 - loss: 0.5315 - precision: 0.8109 - recall: 0.7364\n",
      "Epoch 7: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.7688 - auc: 0.8222 - loss: 0.5330 - precision: 0.8034 - recall: 0.7350 - val_accuracy: 0.7917 - val_auc: 0.8889 - val_loss: 0.4551 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7801 - auc: 0.8140 - loss: 0.5293 - precision: 0.7648 - recall: 0.7978\n",
      "Epoch 8: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7850 - auc: 0.8139 - loss: 0.5275 - precision: 0.7698 - recall: 0.8057 - val_accuracy: 0.7917 - val_auc: 0.8889 - val_loss: 0.4485 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7932 - auc: 0.8999 - loss: 0.4244 - precision: 0.8348 - recall: 0.7632\n",
      "Epoch 9: val_accuracy improved from 0.79167 to 0.83333, saving model to best_mobilenetv2_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.7937 - auc: 0.8921 - loss: 0.4376 - precision: 0.8232 - recall: 0.7707 - val_accuracy: 0.8333 - val_auc: 0.8819 - val_loss: 0.4472 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6741 - auc: 0.7395 - loss: 0.6083 - precision: 0.6262 - recall: 0.7351\n",
      "Epoch 10: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.6905 - auc: 0.7635 - loss: 0.5782 - precision: 0.6482 - recall: 0.7579 - val_accuracy: 0.8333 - val_auc: 0.8785 - val_loss: 0.4435 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8013 - auc: 0.8632 - loss: 0.4417 - precision: 0.7687 - recall: 0.8893\n",
      "Epoch 11: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8080 - auc: 0.8696 - loss: 0.4365 - precision: 0.7729 - recall: 0.8905 - val_accuracy: 0.7917 - val_auc: 0.8819 - val_loss: 0.4355 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8274 - auc: 0.8984 - loss: 0.4147 - precision: 0.8900 - recall: 0.7805\n",
      "Epoch 12: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.8254 - auc: 0.8961 - loss: 0.4158 - precision: 0.8800 - recall: 0.7763 - val_accuracy: 0.7917 - val_auc: 0.8785 - val_loss: 0.4314 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8393 - auc: 0.8941 - loss: 0.4019 - precision: 0.8465 - recall: 0.8375\n",
      "Epoch 13: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8482 - auc: 0.9034 - loss: 0.3841 - precision: 0.8509 - recall: 0.8500 - val_accuracy: 0.7917 - val_auc: 0.8750 - val_loss: 0.4350 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 3.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7946 - auc: 0.8790 - loss: 0.4414 - precision: 0.7947 - recall: 0.7764\n",
      "Epoch 14: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8095 - auc: 0.8789 - loss: 0.4405 - precision: 0.8057 - recall: 0.8033 - val_accuracy: 0.8333 - val_auc: 0.8750 - val_loss: 0.4389 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7857 - auc: 0.8591 - loss: 0.4703 - precision: 0.7704 - recall: 0.8286\n",
      "Epoch 15: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.7976 - auc: 0.8658 - loss: 0.4577 - precision: 0.7802 - recall: 0.8381 - val_accuracy: 0.8333 - val_auc: 0.8750 - val_loss: 0.4316 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8326 - auc: 0.9183 - loss: 0.3575 - precision: 0.8043 - recall: 0.8730\n",
      "Epoch 16: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.8289 - auc: 0.9154 - loss: 0.3635 - precision: 0.7996 - recall: 0.8737 - val_accuracy: 0.7917 - val_auc: 0.8785 - val_loss: 0.4282 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 1.5000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8423 - auc: 0.9237 - loss: 0.3626 - precision: 0.8441 - recall: 0.8327\n",
      "Epoch 17: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.8383 - auc: 0.9246 - loss: 0.3588 - precision: 0.8376 - recall: 0.8349 - val_accuracy: 0.7917 - val_auc: 0.8785 - val_loss: 0.4277 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 1.5000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8482 - auc: 0.9238 - loss: 0.3545 - precision: 0.8690 - recall: 0.8148\n",
      "Epoch 18: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8393 - auc: 0.9207 - loss: 0.3571 - precision: 0.8571 - recall: 0.8111 - val_accuracy: 0.8333 - val_auc: 0.8819 - val_loss: 0.4337 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7961 - auc: 0.9046 - loss: 0.3910 - precision: 0.7699 - recall: 0.8695\n",
      "Epoch 19: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8046 - auc: 0.9098 - loss: 0.3788 - precision: 0.7737 - recall: 0.8773 - val_accuracy: 0.8333 - val_auc: 0.8819 - val_loss: 0.4391 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8460 - auc: 0.9049 - loss: 0.3678 - precision: 0.8028 - recall: 0.9174\n",
      "Epoch 20: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8467 - auc: 0.9067 - loss: 0.3678 - precision: 0.8019 - recall: 0.9211 - val_accuracy: 0.8333 - val_auc: 0.8854 - val_loss: 0.4377 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8917 - auc: 0.9404 - loss: 0.2877 - precision: 0.8708 - recall: 0.9159\n",
      "Epoch 21: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8921 - auc: 0.9420 - loss: 0.2875 - precision: 0.8694 - recall: 0.9201 - val_accuracy: 0.8333 - val_auc: 0.8854 - val_loss: 0.4356 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7961 - auc: 0.8883 - loss: 0.4088 - precision: 0.7958 - recall: 0.8086\n",
      "Epoch 22: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8046 - auc: 0.8899 - loss: 0.4068 - precision: 0.7972 - recall: 0.8248 - val_accuracy: 0.8333 - val_auc: 0.8819 - val_loss: 0.4317 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7991 - auc: 0.8313 - loss: 0.4967 - precision: 0.7735 - recall: 0.8909\n",
      "Epoch 23: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.8155 - auc: 0.8527 - loss: 0.4686 - precision: 0.7889 - recall: 0.8915 - val_accuracy: 0.8333 - val_auc: 0.8854 - val_loss: 0.4236 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8527 - auc: 0.9163 - loss: 0.3504 - precision: 0.8481 - recall: 0.8839\n",
      "Epoch 24: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step - accuracy: 0.8452 - auc: 0.9134 - loss: 0.3578 - precision: 0.8331 - recall: 0.8810 - val_accuracy: 0.8333 - val_auc: 0.8924 - val_loss: 0.4184 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8962 - auc: 0.9190 - loss: 0.3372 - precision: 0.8388 - recall: 0.9821\n",
      "Epoch 25: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8981 - auc: 0.9195 - loss: 0.3342 - precision: 0.8449 - recall: 0.9762 - val_accuracy: 0.7917 - val_auc: 0.8924 - val_loss: 0.4130 - val_precision: 0.7333 - val_recall: 0.9167 - learning_rate: 7.5000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5952 - auc: 0.7054 - loss: 0.6335 - precision: 0.6184 - recall: 0.4623  \n",
      "Epoch 1: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 11s/step - accuracy: 0.5992 - auc: 0.7048 - loss: 0.6396 - precision: 0.6316 - recall: 0.4570 - val_accuracy: 0.8333 - val_auc: 0.8924 - val_loss: 0.4186 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6562 - auc: 0.7019 - loss: 0.6460 - precision: 0.6917 - recall: 0.5244\n",
      "Epoch 2: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6s/step - accuracy: 0.6458 - auc: 0.6953 - loss: 0.6550 - precision: 0.6861 - recall: 0.5103 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4241 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7217 - auc: 0.7707 - loss: 0.6050 - precision: 0.7864 - recall: 0.6236\n",
      "Epoch 3: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7s/step - accuracy: 0.7192 - auc: 0.7699 - loss: 0.6052 - precision: 0.7818 - recall: 0.6181 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4268 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5837 - auc: 0.6627 - loss: 0.6910 - precision: 0.6112 - recall: 0.4598\n",
      "Epoch 4: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.5856 - auc: 0.6653 - loss: 0.6853 - precision: 0.6120 - recall: 0.4673 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4294 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5938 - auc: 0.6519 - loss: 0.6750 - precision: 0.6153 - recall: 0.4077\n",
      "Epoch 5: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.6042 - auc: 0.6675 - loss: 0.6638 - precision: 0.6352 - recall: 0.4325 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4306 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6890 - auc: 0.7863 - loss: 0.5689 - precision: 0.7444 - recall: 0.5774\n",
      "Epoch 6: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8s/step - accuracy: 0.6825 - auc: 0.7787 - loss: 0.5735 - precision: 0.7333 - recall: 0.5754 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4317 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6272 - auc: 0.7470 - loss: 0.6322 - precision: 0.7267 - recall: 0.4976\n",
      "Epoch 7: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.6384 - auc: 0.7461 - loss: 0.6260 - precision: 0.7226 - recall: 0.5103 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4335 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 5.0000e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5781 - auc: 0.7016 - loss: 0.6715 - precision: 0.6367 - recall: 0.3899\n",
      "Epoch 8: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6s/step - accuracy: 0.5938 - auc: 0.7092 - loss: 0.6597 - precision: 0.6559 - recall: 0.4087 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4343 - val_precision: 0.7500 - val_recall: 1.0000 - learning_rate: 2.5000e-06\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - accuracy: 0.8750 - auc: 0.8750 - loss: 0.4290 - precision: 0.8462 - recall: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Final Test Accuracy: 87.50%\n",
      "ğŸ“ˆ AUC: 0.8750 | ğŸ¯ Precision: 0.8462 | ğŸ” Recall: 0.9167\n",
      "âœ… Optimized MobileNetV2 training complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ğŸ“ Paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\MANJU\\\\Desktop\\\\FYP_Diabetes\\\\data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# ğŸ”¢ Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "\n",
    "# ğŸ§ª Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# ğŸ“¦ Data Loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ğŸ“ Class Weight Calculation\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# ğŸ§  Load MobileNetV2 Base\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "base_model.trainable = False  # Initially freeze base model\n",
    "\n",
    "# ğŸ—ï¸ Custom Classifier Head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# ğŸ§ª Compile Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0003),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "\n",
    "# ğŸ“Œ Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_mobilenetv2_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# ğŸš€ Phase 1: Train Custom Head\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stop, lr_scheduler]\n",
    ")\n",
    "\n",
    "# ğŸ”“ Phase 2: Unfreeze and Fine-tune MobileNetV2\n",
    "base_model.trainable = True\n",
    "\n",
    "# Re-compile with lower LR\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "\n",
    "# Fine-tuning Training\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stop, lr_scheduler]\n",
    ")\n",
    "\n",
    "# ğŸ§¾ Evaluate Model\n",
    "loss, accuracy, auc, precision, recall = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"\\nâœ… Final Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ“ˆ AUC: {auc:.4f} | ğŸ¯ Precision: {precision:.4f} | ğŸ” Recall: {recall:.4f}\")\n",
    "\n",
    "# ğŸ’¾ Save Final Model\n",
    "model.save(\"final_mobilenetv2_model.h5\")\n",
    "print(\"âœ… Optimized MobileNetV2 training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
