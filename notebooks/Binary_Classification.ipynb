{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANJU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4461 - auc: 0.4301 - loss: 0.7198 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_efficientnetb3_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6s/step - accuracy: 0.4444 - auc: 0.4356 - loss: 0.7195 - val_accuracy: 0.5000 - val_auc: 0.2500 - val_loss: 0.7030\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4147 - auc: 0.3937 - loss: 0.7317\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.4211 - auc: 0.3974 - loss: 0.7290 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4875 - auc: 0.4487 - loss: 0.7128\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.4936 - auc: 0.4594 - loss: 0.7109 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4229 - auc: 0.3655 - loss: 0.7201\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.4222 - auc: 0.3698 - loss: 0.7197 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6935\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5045 - auc: 0.5215 - loss: 0.7010\n",
      "Epoch 5: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5071 - auc: 0.5158 - loss: 0.7018 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6923\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5281 - auc: 0.5621 - loss: 0.6846\n",
      "Epoch 6: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.5350 - auc: 0.5646 - loss: 0.6848 - val_accuracy: 0.5000 - val_auc: 0.6667 - val_loss: 0.6957\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4585 - auc: 0.4708 - loss: 0.7175\n",
      "Epoch 7: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - accuracy: 0.4597 - auc: 0.4694 - loss: 0.7168 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6921\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6291 - auc: 0.6613 - loss: 0.6589\n",
      "Epoch 8: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.6211 - auc: 0.6558 - loss: 0.6608 - val_accuracy: 0.5000 - val_auc: 0.6667 - val_loss: 0.6924\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3927 - auc: 0.3944 - loss: 0.7334\n",
      "Epoch 9: val_accuracy improved from 0.50000 to 0.75000, saving model to best_efficientnetb3_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6s/step - accuracy: 0.3928 - auc: 0.3932 - loss: 0.7332 - val_accuracy: 0.7500 - val_auc: 0.5799 - val_loss: 0.6916\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5890 - auc: 0.5223 - loss: 0.7050\n",
      "Epoch 10: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.5890 - auc: 0.5267 - loss: 0.7033 - val_accuracy: 0.5000 - val_auc: 0.7083 - val_loss: 0.6964\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5708 - auc: 0.5203 - loss: 0.7060\n",
      "Epoch 11: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.5692 - auc: 0.5217 - loss: 0.7062 - val_accuracy: 0.5000 - val_auc: 0.5799 - val_loss: 0.6957\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5155 - auc: 0.4520 - loss: 0.7179\n",
      "Epoch 12: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - accuracy: 0.5106 - auc: 0.4576 - loss: 0.7166 - val_accuracy: 0.5000 - val_auc: 0.5833 - val_loss: 0.6918\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4488 - auc: 0.4948 - loss: 0.7021\n",
      "Epoch 13: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4484 - auc: 0.4919 - loss: 0.7026 - val_accuracy: 0.5000 - val_auc: 0.6667 - val_loss: 0.6939\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5307 - auc: 0.5514 - loss: 0.6970\n",
      "Epoch 14: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5335 - auc: 0.5524 - loss: 0.6957 - val_accuracy: 0.5000 - val_auc: 0.5799 - val_loss: 0.6936\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5219 - auc: 0.4704 - loss: 0.7043\n",
      "Epoch 15: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.5175 - auc: 0.4717 - loss: 0.7050 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6931\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4984 - auc: 0.5461 - loss: 0.6914\n",
      "Epoch 16: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5113 - auc: 0.5538 - loss: 0.6894 - val_accuracy: 0.5000 - val_auc: 0.5417 - val_loss: 0.6926\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4557 - auc: 0.4633 - loss: 0.7105\n",
      "Epoch 17: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.4521 - auc: 0.4617 - loss: 0.7112 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6950\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5339 - auc: 0.4453 - loss: 0.7144\n",
      "Epoch 18: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5343 - auc: 0.4524 - loss: 0.7132 - val_accuracy: 0.5000 - val_auc: 0.7083 - val_loss: 0.6946\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4906 - auc: 0.5120 - loss: 0.6975\n",
      "Epoch 19: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.4853 - auc: 0.5078 - loss: 0.6978 - val_accuracy: 0.5000 - val_auc: 0.6667 - val_loss: 0.6930\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6250 - auc: 0.6076 - loss: 0.6924\n",
      "\n",
      "✅ Test Accuracy: 62.50%\n",
      "✅ Test AUC Score: 0.6076\n",
      "✅ Model training and saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# 📁 Paths\n",
    "BASE_DIR = \"C:/Users/MANJU/Desktop/FYP_Diabetes/data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# 📐 Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 300, 300  # EfficientNetB3 image size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# 🔁 Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'  # ✅ Binary Classification\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ⚙️ Load EfficientNetB3 base model\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "# 🎯 Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  # ✅ Binary output\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# 🔧 Compile\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# 📦 Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_efficientnetb3_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 🚀 Train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")\n",
    "\n",
    "# 📊 Evaluate\n",
    "loss, accuracy, auc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"\\n✅ Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"✅ Test AUC Score: {auc:.4f}\")\n",
    "\n",
    "# 💾 Save Final Model\n",
    "model.save(\"final_efficientnetb3_model.keras\")\n",
    "print(\"✅ Model training and saving completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
