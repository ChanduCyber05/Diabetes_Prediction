{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANJU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5078 - auc: 0.4504 - loss: 0.7498 - precision: 0.4848 - recall: 0.2411  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.79167, saving model to best_effnetb3_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 15s/step - accuracy: 0.5260 - auc: 0.4771 - loss: 0.7387 - precision: 0.5253 - recall: 0.2798 - val_accuracy: 0.7917 - val_auc: 0.8993 - val_loss: 0.5759 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6786 - auc: 0.7596 - loss: 0.5981 - precision: 0.6450 - recall: 0.8403\n",
      "Epoch 2: val_accuracy improved from 0.79167 to 0.83333, saving model to best_effnetb3_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9s/step - accuracy: 0.6756 - auc: 0.7483 - loss: 0.6054 - precision: 0.6378 - recall: 0.8459 - val_accuracy: 0.8333 - val_auc: 0.8958 - val_loss: 0.5055 - val_precision: 0.8333 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8616 - auc: 0.8841 - loss: 0.4631 - precision: 0.8093 - recall: 0.9532\n",
      "Epoch 3: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8571 - auc: 0.8803 - loss: 0.4638 - precision: 0.8032 - recall: 0.9510 - val_accuracy: 0.7500 - val_auc: 0.8958 - val_loss: 0.4844 - val_precision: 0.8000 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8467 - auc: 0.8861 - loss: 0.4423 - precision: 0.8229 - recall: 0.8571\n",
      "Epoch 4: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8442 - auc: 0.8819 - loss: 0.4444 - precision: 0.8245 - recall: 0.8571 - val_accuracy: 0.7500 - val_auc: 0.8889 - val_loss: 0.4820 - val_precision: 0.8000 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8274 - auc: 0.9031 - loss: 0.4055 - precision: 0.8114 - recall: 0.7965\n",
      "Epoch 5: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8254 - auc: 0.9038 - loss: 0.4067 - precision: 0.8187 - recall: 0.7989 - val_accuracy: 0.7500 - val_auc: 0.8889 - val_loss: 0.4726 - val_precision: 0.8000 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7798 - auc: 0.8525 - loss: 0.4501 - precision: 0.7818 - recall: 0.8175\n",
      "Epoch 6: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.7966 - auc: 0.8669 - loss: 0.4329 - precision: 0.7924 - recall: 0.8307 - val_accuracy: 0.7500 - val_auc: 0.8889 - val_loss: 0.4425 - val_precision: 0.8000 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8676 - auc: 0.9364 - loss: 0.3190 - precision: 0.8596 - recall: 0.8780\n",
      "Epoch 7: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9s/step - accuracy: 0.8581 - auc: 0.9291 - loss: 0.3317 - precision: 0.8529 - recall: 0.8651 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4276 - val_precision: 0.8333 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8854 - auc: 0.9407 - loss: 0.3135 - precision: 0.8516 - recall: 0.9297\n",
      "Epoch 8: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8819 - auc: 0.9363 - loss: 0.3203 - precision: 0.8438 - recall: 0.9353 - val_accuracy: 0.8333 - val_auc: 0.8889 - val_loss: 0.4241 - val_precision: 0.8333 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8292 - auc: 0.9315 - loss: 0.3259 - precision: 0.8071 - recall: 0.8909\n",
      "Epoch 9: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7s/step - accuracy: 0.8296 - auc: 0.9313 - loss: 0.3286 - precision: 0.8026 - recall: 0.8915 - val_accuracy: 0.7917 - val_auc: 0.8889 - val_loss: 0.4228 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8155 - auc: 0.9194 - loss: 0.3456 - precision: 0.7831 - recall: 0.8720\n",
      "Epoch 10: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8234 - auc: 0.9208 - loss: 0.3418 - precision: 0.7877 - recall: 0.8849 - val_accuracy: 0.7917 - val_auc: 0.8889 - val_loss: 0.4245 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8021 - auc: 0.9251 - loss: 0.3458 - precision: 0.7689 - recall: 0.8505\n",
      "Epoch 11: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8056 - auc: 0.9257 - loss: 0.3451 - precision: 0.7719 - recall: 0.8587 - val_accuracy: 0.7917 - val_auc: 0.8889 - val_loss: 0.4267 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8542 - auc: 0.9293 - loss: 0.3278 - precision: 0.8301 - recall: 0.9066\n",
      "Epoch 12: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9s/step - accuracy: 0.8611 - auc: 0.9340 - loss: 0.3168 - precision: 0.8329 - recall: 0.9139 - val_accuracy: 0.7917 - val_auc: 0.8958 - val_loss: 0.4314 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 3.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8371 - auc: 0.9273 - loss: 0.3199 - precision: 0.8428 - recall: 0.8502\n",
      "Epoch 13: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7s/step - accuracy: 0.8348 - auc: 0.9294 - loss: 0.3205 - precision: 0.8367 - recall: 0.8466 - val_accuracy: 0.7917 - val_auc: 0.8958 - val_loss: 0.4326 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 1.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8557 - auc: 0.9471 - loss: 0.3088 - precision: 0.8017 - recall: 0.9375\n",
      "Epoch 14: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.8562 - auc: 0.9469 - loss: 0.3064 - precision: 0.8161 - recall: 0.9167 - val_accuracy: 0.7917 - val_auc: 0.8993 - val_loss: 0.4342 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 1.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8601 - auc: 0.9547 - loss: 0.2804 - precision: 0.8237 - recall: 0.9010\n",
      "Epoch 15: val_accuracy did not improve from 0.83333\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9s/step - accuracy: 0.8621 - auc: 0.9532 - loss: 0.2828 - precision: 0.8316 - recall: 0.8983 - val_accuracy: 0.7917 - val_auc: 0.9028 - val_loss: 0.4344 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 1.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9226 - auc: 0.9676 - loss: 0.2563 - precision: 0.9085 - recall: 0.9560\n",
      "Epoch 16: val_accuracy did not improve from 0.83333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9s/step - accuracy: 0.9246 - auc: 0.9692 - loss: 0.2519 - precision: 0.9103 - recall: 0.9528 - val_accuracy: 0.7917 - val_auc: 0.9028 - val_loss: 0.4344 - val_precision: 0.7692 - val_recall: 0.8333 - learning_rate: 7.5000e-05\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ğŸ“ Paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\MANJU\\\\Desktop\\\\FYP_Diabetes\\\\data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# ğŸ”¢ Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 300, 300  # EfficientNetB3 prefers higher resolution\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "# ğŸ§ª Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# ğŸ“¦ Data Loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ğŸ“ Class Weight Calculation\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# ğŸ§  Load EfficientNetB3 Base Model\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# ğŸ—ï¸ Custom Classifier\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# ğŸ§ª Compile Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0003),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
    ")\n",
    "\n",
    "# ğŸ“Œ Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_effnetb3_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# ğŸš€ Train Phase 1: Feature Extraction\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stop, lr_scheduler]\n",
    ")\n",
    "\n",
    "# ğŸ”“ Unfreeze for Fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile with lower LR\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
    ")\n",
    "\n",
    "# ğŸš€ Train Phase 2: Fine-Tuning\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stop, lr_scheduler]\n",
    ")\n",
    "\n",
    "# ğŸ§¾ Final Evaluation\n",
    "loss, accuracy, auc, precision, recall = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"\\nâœ… Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"ğŸ“ˆ AUC: {auc:.4f} | ğŸ¯ Precision: {precision:.4f} | ğŸ” Recall: {recall:.4f}\")\n",
    "\n",
    "# ğŸ’¾ Save Final Model\n",
    "model.save(\"final_effnetb3_model.h5\")\n",
    "print(\"âœ… Model training completed with high accuracy!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
