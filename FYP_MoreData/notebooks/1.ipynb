{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANJU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10s/step - accuracy: 0.6476 - loss: 0.7774 - val_accuracy: 0.5833 - val_loss: 0.6867 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.6613 - loss: 0.6191 - val_accuracy: 0.6250 - val_loss: 0.6966 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9s/step - accuracy: 0.6492 - loss: 0.5689 - val_accuracy: 0.6667 - val_loss: 0.6718 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8s/step - accuracy: 0.7589 - loss: 0.5397 - val_accuracy: 0.6667 - val_loss: 0.6307 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8s/step - accuracy: 0.7838 - loss: 0.4877 - val_accuracy: 0.6667 - val_loss: 0.6155 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8s/step - accuracy: 0.7835 - loss: 0.4547 - val_accuracy: 0.6875 - val_loss: 0.6659 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.8235 - loss: 0.4411 - val_accuracy: 0.6667 - val_loss: 0.7188 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7978 - loss: 0.4257\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.7958 - loss: 0.4268 - val_accuracy: 0.6667 - val_loss: 0.7130 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8s/step - accuracy: 0.8181 - loss: 0.4225 - val_accuracy: 0.6667 - val_loss: 0.7110 - learning_rate: 1.5000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7s/step - accuracy: 0.7933 - loss: 0.4069 - val_accuracy: 0.6667 - val_loss: 0.7057 - learning_rate: 1.5000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7747 - loss: 0.3934\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.7799 - loss: 0.3941 - val_accuracy: 0.6667 - val_loss: 0.6768 - learning_rate: 1.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.8262 - loss: 0.3604 - val_accuracy: 0.6667 - val_loss: 0.6620 - learning_rate: 7.5000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 152s/step - accuracy: 0.6112 - loss: 0.6384 - val_accuracy: 0.6458 - val_loss: 0.5957 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 125s/step - accuracy: 0.7025 - loss: 0.5698 - val_accuracy: 0.6458 - val_loss: 0.5774 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Average, Input\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ğŸ“ Paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\MANJU\\\\Desktop\\\\FYP_Moredata\\\\split_data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# ğŸ”¢ Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_PHASE1 = 20\n",
    "EPOCHS_PHASE2 = 10\n",
    "\n",
    "# ğŸ§ª Preprocessing (choose one common function)\n",
    "preprocess_func = efficientnet_preprocess  # works well for both models\n",
    "\n",
    "# ğŸ§ª Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_func,\n",
    "    rotation_range=40, shear_range=0.2, zoom_range=0.2,\n",
    "    brightness_range=(0.5, 1.5), horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "\n",
    "# ğŸ“¦ Data Loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
    "\n",
    "# âš–ï¸ Class Weights\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(train_generator.classes),\n",
    "                                     y=train_generator.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# ğŸ§  Ensemble Model Definition\n",
    "input_tensor = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# ResNet50 branch\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "resnet_base.trainable = False\n",
    "x1 = resnet_base.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(64, activation='relu')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "resnet_out = Dense(1, activation='sigmoid')(x1)\n",
    "\n",
    "# EfficientNetB0 branch (same input)\n",
    "efficient_base = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "efficient_base.trainable = False\n",
    "x2 = efficient_base.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = Dense(64, activation='relu')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "efficient_out = Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "# ğŸ§  Final Output (Averaged prediction)\n",
    "avg_output = Average()([resnet_out, efficient_out])\n",
    "\n",
    "# âœ… Define Full Model\n",
    "model = Model(inputs=input_tensor, outputs=avg_output)\n",
    "\n",
    "# âš™ï¸ Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ğŸ“Œ Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# ğŸš€ Phase 1: Train custom head\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=EPOCHS_PHASE1,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=len(val_generator),\n",
    "          class_weight=class_weights,\n",
    "          callbacks=[early_stop, lr_scheduler])\n",
    "\n",
    "# ğŸ”“ Phase 2: Fine-tuning both branches\n",
    "resnet_base.trainable = True\n",
    "efficient_base.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=EPOCHS_PHASE2,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=len(val_generator),\n",
    "          class_weight=class_weights,\n",
    "          callbacks=[early_stop, lr_scheduler])\n",
    "\n",
    "# ğŸ§¾ Final Evaluation\n",
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"\\nâœ… Final Test Accuracy of Ensemble Model (ResNet50 + EfficientNetB0): {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
