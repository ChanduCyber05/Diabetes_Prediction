{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226 images belonging to 2 classes.\n",
      "Found 48 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANJU\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 10s/step - accuracy: 0.6476 - loss: 0.7774 - val_accuracy: 0.5833 - val_loss: 0.6867 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.6613 - loss: 0.6191 - val_accuracy: 0.6250 - val_loss: 0.6966 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9s/step - accuracy: 0.6492 - loss: 0.5689 - val_accuracy: 0.6667 - val_loss: 0.6718 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8s/step - accuracy: 0.7589 - loss: 0.5397 - val_accuracy: 0.6667 - val_loss: 0.6307 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8s/step - accuracy: 0.7838 - loss: 0.4877 - val_accuracy: 0.6667 - val_loss: 0.6155 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8s/step - accuracy: 0.7835 - loss: 0.4547 - val_accuracy: 0.6875 - val_loss: 0.6659 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.8235 - loss: 0.4411 - val_accuracy: 0.6667 - val_loss: 0.7188 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7978 - loss: 0.4257\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.7958 - loss: 0.4268 - val_accuracy: 0.6667 - val_loss: 0.7130 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8s/step - accuracy: 0.8181 - loss: 0.4225 - val_accuracy: 0.6667 - val_loss: 0.7110 - learning_rate: 1.5000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 7s/step - accuracy: 0.7933 - loss: 0.4069 - val_accuracy: 0.6667 - val_loss: 0.7057 - learning_rate: 1.5000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7747 - loss: 0.3934\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.7799 - loss: 0.3941 - val_accuracy: 0.6667 - val_loss: 0.6768 - learning_rate: 1.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7s/step - accuracy: 0.8262 - loss: 0.3604 - val_accuracy: 0.6667 - val_loss: 0.6620 - learning_rate: 7.5000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 152s/step - accuracy: 0.6112 - loss: 0.6384 - val_accuracy: 0.6458 - val_loss: 0.5957 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 125s/step - accuracy: 0.7025 - loss: 0.5698 - val_accuracy: 0.6458 - val_loss: 0.5774 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Average, Input\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 📁 Paths\n",
    "BASE_DIR = \"C:\\\\Users\\\\MANJU\\\\Desktop\\\\FYP_Moredata\\\\split_data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# 🔢 Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_PHASE1 = 20\n",
    "EPOCHS_PHASE2 = 10\n",
    "\n",
    "# 🧪 Preprocessing (choose one common function)\n",
    "preprocess_func = efficientnet_preprocess  # works well for both models\n",
    "\n",
    "# 🧪 Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_func,\n",
    "    rotation_range=40, shear_range=0.2, zoom_range=0.2,\n",
    "    brightness_range=(0.5, 1.5), horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "\n",
    "# 📦 Data Loaders\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
    "\n",
    "# ⚖️ Class Weights\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(train_generator.classes),\n",
    "                                     y=train_generator.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# 🧠 Ensemble Model Definition\n",
    "input_tensor = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# ResNet50 branch\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "resnet_base.trainable = False\n",
    "x1 = resnet_base.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(64, activation='relu')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "resnet_out = Dense(1, activation='sigmoid')(x1)\n",
    "\n",
    "# EfficientNetB0 branch (same input)\n",
    "efficient_base = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "efficient_base.trainable = False\n",
    "x2 = efficient_base.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = Dense(64, activation='relu')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "efficient_out = Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "# 🧠 Final Output (Averaged prediction)\n",
    "avg_output = Average()([resnet_out, efficient_out])\n",
    "\n",
    "# ✅ Define Full Model\n",
    "model = Model(inputs=input_tensor, outputs=avg_output)\n",
    "\n",
    "# ⚙️ Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 📌 Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# 🚀 Phase 1: Train custom head\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=EPOCHS_PHASE1,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=len(val_generator),\n",
    "          class_weight=class_weights,\n",
    "          callbacks=[early_stop, lr_scheduler])\n",
    "\n",
    "# 🔓 Phase 2: Fine-tuning both branches\n",
    "resnet_base.trainable = True\n",
    "efficient_base.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          epochs=EPOCHS_PHASE2,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=len(val_generator),\n",
    "          class_weight=class_weights,\n",
    "          callbacks=[early_stop, lr_scheduler])\n",
    "\n",
    "# 🧾 Final Evaluation\n",
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f\"\\n✅ Final Test Accuracy of Ensemble Model (ResNet50 + EfficientNetB0): {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
